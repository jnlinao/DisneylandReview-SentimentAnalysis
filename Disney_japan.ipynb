{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd038dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82bb9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "japan = pd.read_csv('japan_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e76950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>tb_polarity</th>\n",
       "      <th>tb_subjectivity</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_comp</th>\n",
       "      <th>...</th>\n",
       "      <th>word_yourselves</th>\n",
       "      <th>word_youth</th>\n",
       "      <th>word_yr</th>\n",
       "      <th>word_yrs</th>\n",
       "      <th>word_yum</th>\n",
       "      <th>word_yummy</th>\n",
       "      <th>word_zero</th>\n",
       "      <th>word_zone</th>\n",
       "      <th>word_zones</th>\n",
       "      <th>R_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tokyo disneyland is truly the happiest place o...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-22</td>\n",
       "      <td>japan</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.677619</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glad to visit not so many people on sunday th ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-04</td>\n",
       "      <td>japan</td>\n",
       "      <td>0.288154</td>\n",
       "      <td>0.624656</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my fiance her best friend and i went here the ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-11-28</td>\n",
       "      <td>japan</td>\n",
       "      <td>0.205093</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ouh mh godd we are veryy love this placee so s...</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>japan</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i brought my daughter to tokyo disneyland alth...</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>japan</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.429940</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0  tokyo disneyland is truly the happiest place o...       5  2021-05-22   \n",
       "1  glad to visit not so many people on sunday th ...       5  2021-04-04   \n",
       "2  my fiance her best friend and i went here the ...       5  2020-11-28   \n",
       "3  ouh mh godd we are veryy love this placee so s...       5  2020-10-17   \n",
       "4  i brought my daughter to tokyo disneyland alth...       1  2020-10-16   \n",
       "\n",
       "    name  tb_polarity  tb_subjectivity  vader_pos  vader_neu  vader_neg  \\\n",
       "0  japan     0.485714         0.677619      0.290      0.710      0.000   \n",
       "1  japan     0.288154         0.624656      0.208      0.792      0.000   \n",
       "2  japan     0.205093         0.351852      0.130      0.804      0.066   \n",
       "3  japan     0.500000         0.566667      0.315      0.685      0.000   \n",
       "4  japan     0.071000         0.429940      0.181      0.708      0.112   \n",
       "\n",
       "   vader_comp  ... word_yourselves word_youth  word_yr  word_yrs  word_yum  \\\n",
       "0      0.9729  ...             0.0        0.0      0.0       0.0       0.0   \n",
       "1      0.9823  ...             0.0        0.0      0.0       0.0       0.0   \n",
       "2      0.8100  ...             0.0        0.0      0.0       0.0       0.0   \n",
       "3      0.9100  ...             0.0        0.0      0.0       0.0       0.0   \n",
       "4      0.8927  ...             0.0        0.0      0.0       0.0       0.0   \n",
       "\n",
       "   word_yummy  word_zero  word_zone  word_zones  R_Rating  \n",
       "0         0.0        0.0        0.0         0.0         1  \n",
       "1         0.0        0.0        0.0         0.0         1  \n",
       "2         0.0        0.0        0.0         0.0         1  \n",
       "3         0.0        0.0        0.0         0.0         1  \n",
       "4         0.0        0.0        0.0         0.0         0  \n",
       "\n",
       "[5 rows x 4521 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "japan.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c868bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3230, 4521)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "japan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be6af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!pip install -U textblob\n",
    "#!pip install vaderSentiment\n",
    "import spacy\n",
    "import tabulate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import confusion_matrix, precision_score, precision_recall_curve, recall_score, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3c47a",
   "metadata": {},
   "source": [
    "### Japan data_ Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27407ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = japan[\"R_Rating\"]\n",
    "X = japan.drop([\"R_Rating\",\"Vader_Rating\",\"Review_Rating\", \"review\", \"name\", \"date\", \"rating\"\n",
    "              ,\"tb_polarity\",\"tb_subjectivity\",\"vader_pos\",\"vader_neu\",\"vader_neg\",\"vader_comp\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e486b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_words</th>\n",
       "      <th>doc2vec_vector_0</th>\n",
       "      <th>doc2vec_vector_1</th>\n",
       "      <th>doc2vec_vector_2</th>\n",
       "      <th>doc2vec_vector_3</th>\n",
       "      <th>doc2vec_vector_4</th>\n",
       "      <th>word_ability</th>\n",
       "      <th>word_abit</th>\n",
       "      <th>word_able</th>\n",
       "      <th>...</th>\n",
       "      <th>word_yourself</th>\n",
       "      <th>word_yourselves</th>\n",
       "      <th>word_youth</th>\n",
       "      <th>word_yr</th>\n",
       "      <th>word_yrs</th>\n",
       "      <th>word_yum</th>\n",
       "      <th>word_yummy</th>\n",
       "      <th>word_zero</th>\n",
       "      <th>word_zone</th>\n",
       "      <th>word_zones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335</td>\n",
       "      <td>65</td>\n",
       "      <td>0.024619</td>\n",
       "      <td>0.347973</td>\n",
       "      <td>0.093240</td>\n",
       "      <td>-0.628225</td>\n",
       "      <td>0.273338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>583</td>\n",
       "      <td>112</td>\n",
       "      <td>-0.288998</td>\n",
       "      <td>0.447758</td>\n",
       "      <td>-0.861468</td>\n",
       "      <td>-0.106545</td>\n",
       "      <td>-0.187401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>102</td>\n",
       "      <td>0.589929</td>\n",
       "      <td>0.745137</td>\n",
       "      <td>-0.968216</td>\n",
       "      <td>-0.606862</td>\n",
       "      <td>0.278940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>29</td>\n",
       "      <td>0.221496</td>\n",
       "      <td>0.880633</td>\n",
       "      <td>-0.244433</td>\n",
       "      <td>-0.818276</td>\n",
       "      <td>-0.051795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1102</td>\n",
       "      <td>182</td>\n",
       "      <td>1.112031</td>\n",
       "      <td>0.815125</td>\n",
       "      <td>0.418955</td>\n",
       "      <td>-1.044916</td>\n",
       "      <td>0.271630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_chars  n_words  doc2vec_vector_0  doc2vec_vector_1  doc2vec_vector_2  \\\n",
       "0      335       65          0.024619          0.347973          0.093240   \n",
       "1      583      112         -0.288998          0.447758         -0.861468   \n",
       "2      500      102          0.589929          0.745137         -0.968216   \n",
       "3      128       29          0.221496          0.880633         -0.244433   \n",
       "4     1102      182          1.112031          0.815125          0.418955   \n",
       "\n",
       "   doc2vec_vector_3  doc2vec_vector_4  word_ability  word_abit  word_able  \\\n",
       "0         -0.628225          0.273338           0.0        0.0        0.0   \n",
       "1         -0.106545         -0.187401           0.0        0.0        0.0   \n",
       "2         -0.606862          0.278940           0.0        0.0        0.0   \n",
       "3         -0.818276         -0.051795           0.0        0.0        0.0   \n",
       "4         -1.044916          0.271630           0.0        0.0        0.0   \n",
       "\n",
       "   ...  word_yourself  word_yourselves  word_youth  word_yr  word_yrs  \\\n",
       "0  ...            0.0              0.0         0.0      0.0       0.0   \n",
       "1  ...            0.0              0.0         0.0      0.0       0.0   \n",
       "2  ...            0.0              0.0         0.0      0.0       0.0   \n",
       "3  ...            0.0              0.0         0.0      0.0       0.0   \n",
       "4  ...            0.0              0.0         0.0      0.0       0.0   \n",
       "\n",
       "   word_yum  word_yummy  word_zero  word_zone  word_zones  \n",
       "0       0.0         0.0        0.0        0.0         0.0  \n",
       "1       0.0         0.0        0.0        0.0         0.0  \n",
       "2       0.0         0.0        0.0        0.0         0.0  \n",
       "3       0.0         0.0        0.0        0.0         0.0  \n",
       "4       0.0         0.0        0.0        0.0         0.0  \n",
       "\n",
       "[5 rows x 4508 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87400a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3230, 4508)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1ada36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee58af",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3d6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#undersampling\n",
    "under = RandomUnderSampler(sampling_strategy=0.5,random_state= 42)\n",
    "X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "steps = [('under', under)]\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf202f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train  = pipeline.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a970a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test= sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "897ebb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    896\n",
       "0    448\n",
       "Name: R_Rating, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678dc486",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2637a",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "569d8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2d96a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.854\n",
      "Recall: 0.971\n",
      "Accuracy: 0.842\n",
      "F1 Score: 0.909\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "print('Precision: %.3f' % precision_score(y_test, rf_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, rf_pred))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, rf_pred))\n",
    "print('F1 Score: %.3f' % f1_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d35b74ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.28      0.40       121\n",
      "           1       0.85      0.97      0.91       525\n",
      "\n",
      "    accuracy                           0.84       646\n",
      "   macro avg       0.77      0.63      0.65       646\n",
      "weighted avg       0.82      0.84      0.81       646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84995368",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22fbb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xg = XGBClassifier(objective= 'binary:logistic', n_estimators = 100, random_state = 42)\n",
    "xg.fit(X_train, y_train)\n",
    "xg_pred = xg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a62897e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.911\n",
      "Recall: 0.897\n",
      "Accuracy: 0.845\n",
      "F1 Score: 0.904\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "print('Precision: %.3f' % precision_score(y_test, xg_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, xg_pred))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, xg_pred))\n",
    "print('F1 Score: %.3f' % f1_score(y_test, xg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa87cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60       121\n",
      "           1       0.91      0.90      0.90       525\n",
      "\n",
      "    accuracy                           0.85       646\n",
      "   macro avg       0.75      0.76      0.75       646\n",
      "weighted avg       0.85      0.85      0.85       646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, xg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b820cf93",
   "metadata": {},
   "source": [
    "#### XGBoost hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bccb1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# declare parameters\n",
    "parameters = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=parameters,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = 10,\n",
    "    cv = 10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7a07ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, seed=42,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=10,\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.05],\n",
       "                         'max_depth': range(2, 10),\n",
       "                         'n_estimators': range(60, 220, 40)},\n",
       "             scoring='roc_auc', verbose=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bf93648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=180, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=42, subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36b2e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgt = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=180, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "              random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "              seed=42, subsample=1, tree_method='exact', validate_parameters=1,\n",
    "              verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeaa6d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.902\n",
      "Recall: 0.910\n",
      "Accuracy: 0.847\n",
      "F1 Score: 0.906\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "print('Precision: %.3f' % precision_score(y_test, xgt_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, xgt_pred))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, xgt_pred))\n",
    "print('F1 Score: %.3f' % f1_score(y_test, xgt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "275456f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_test, xgt_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d466825",
   "metadata": {},
   "source": [
    "#feature importance plot\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "plot_importance(xgt, max_num_features=10)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f658b",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a1308c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train, y_train)\n",
    "\n",
    "lg_pred = lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8b141e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.895\n",
      "Recall: 0.848\n",
      "Accuracy: 0.796\n",
      "F1 Score: 0.871\n"
     ]
    }
   ],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, lg_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, lg_pred))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, lg_pred))\n",
    "print('F1 Score: %.3f' % f1_score(y_test, lg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43305076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.57      0.51       121\n",
      "           1       0.90      0.85      0.87       525\n",
      "\n",
      "    accuracy                           0.80       646\n",
      "   macro avg       0.68      0.71      0.69       646\n",
      "weighted avg       0.81      0.80      0.80       646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca316c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
